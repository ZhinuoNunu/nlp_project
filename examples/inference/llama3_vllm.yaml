model_name_or_path: /home/ubuntu/.cache/modelscope/hub/LLM-Research/Meta-Llama-3___1-8B-Instruct
template: llama3
infer_backend: vllm
vllm_enforce_eager: true
cutoff_len: 4096